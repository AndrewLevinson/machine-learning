{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "from skimage import io, color, transform, feature, filters, exposure\n",
    "import my_measures # note, this was updated March 27; make sure you are using the current version! \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths/names\n",
    "\n",
    "root_dir = '/Users/andrewlevinson'\n",
    "\n",
    "\n",
    "ci_path = root_dir + '/programs/parsons/spring-2019/machine-learning-class/machine-learning/assignment-2/data/plane_data/cropped_images_18/' # cropped images for training\n",
    "l_file = root_dir + '/programs/parsons/spring-2019/machine-learning-class/machine-learning/assignment-2/data/plane_data/plane_labels_2018.csv' # csv with labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get labels and extract features from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   img_name  plane\n",
      "0  2016-08-02T13+50+24_430Z  False\n",
      "1  2016-08-02T14+12+37_390Z  False\n",
      "2  2016-08-02T22+20+26_600Z  False\n",
      "3  2016-08-03T12+04+30_670Z  False\n",
      "4  2016-08-03T12+32+21_790Z  False\n",
      "(6758, 2)\n"
     ]
    }
   ],
   "source": [
    "# all labels\n",
    "plane_data = pd.read_csv(l_file)\n",
    "print(plane_data.head())\n",
    "print(plane_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in downscaling the image, what do you want the new dimensions to be?\n",
    "# the original dimensions of cropped images: (60, 140), which if 8,400 pixels\n",
    "dims = (15, 35) # 25% of the original size, 525 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downscaled image shape: \n",
      "(15, 35)\n",
      "image representation (first row of pixels): \n",
      "[0.0128704  0.03454539 0.01798674 0.01217119 0.01307643 0.04977653\n",
      " 0.04464198 0.01368112 0.0561465  0.05557257 0.05096334 0.01997029\n",
      " 0.0358638  0.0507699  0.07061674 0.02922448 0.01953835 0.03196072\n",
      " 0.04666997 0.02118598 0.02320723 0.05021895 0.04438741 0.03130091\n",
      " 0.02151537 0.06768397 0.07421185 0.03935413 0.14791857 0.18967169\n",
      " 0.47074266 0.09580797 0.         0.         0.        ]\n",
      "\n",
      "\n",
      "example of transformation: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scikit-image documentation on methods used for feature extraction: \n",
    "#    http://scikit-image.org/docs/dev/api/skimage.color.html#rgb2gray\n",
    "#    http://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.resize\n",
    "#    http://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.canny\n",
    "\n",
    "def image_manipulation(imname, imview=False):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    imname = ci_path + imname + '.png'\n",
    "    img_raw = io.imread(imname)\n",
    "    \n",
    "    tup, hist = feature.hog(img_raw, orientations=16, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True, transform_sqrt=True, multichannel=True) #http://scikit-image.org/docs/dev/api/skimage.feature.html#hog \n",
    "    downscaled = transform.resize(hist, (dims[0], dims[1])) # downscale image\n",
    "    final_image = downscaled\n",
    "    \n",
    "    if imview==True:\n",
    "        io.imshow(final_image)\n",
    "    warnings.filterwarnings('always')\n",
    "    return final_image\n",
    "\n",
    "# test the function, look at input/output\n",
    "test_image = image_manipulation('2017-08-25T23+24+13_390Z', True)\n",
    "print('downscaled image shape: ')\n",
    "print(test_image.shape)\n",
    "print('image representation (first row of pixels): ')\n",
    "print(test_image[1])\n",
    "print('\\n')\n",
    "print('example of transformation: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct lists for features, labels, and a crosswalk reference to image names\n",
    "\n",
    "features_list = []\n",
    "y_list = []\n",
    "imnames_list = []\n",
    "\n",
    "for index, row in plane_data.iterrows():\n",
    "    features_list.append(image_manipulation(row['img_name']))\n",
    "    y_list.append(row['plane'])\n",
    "    imnames_list.append(row['img_name'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the lists to ndarrays\n",
    "features = np.asarray(features_list)\n",
    "Y = np.asarray(y_list)\n",
    "imgs = np.asarray(imnames_list)\n",
    "print('Shape of original feature representation: ')\n",
    "print(features.shape)\n",
    "\n",
    "# flatten the images ndarray to one row per image\n",
    "features_flat = features.reshape((features.shape[0], -1))\n",
    "\n",
    "print('Shape of flat feature representation: ')\n",
    "print(features_flat.shape)\n",
    "\n",
    "print('Shape of Y: ')\n",
    "print(Y.shape)\n",
    "\n",
    "print('Number of images with planes: ')\n",
    "print(Y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# enter an integer for random_state\n",
    "data_train, data_test, y_train, y_test, imgs_train, imgs_test = train_test_split(features_flat, \n",
    "    Y, imgs, test_size = 0.25, random_state = 6)\n",
    "\n",
    "print('Shape of training set: ')\n",
    "print(y_train.shape)\n",
    "print('Number of training images that contain an airplane: ')\n",
    "print(y_train.sum())\n",
    "\n",
    "print(' ')\n",
    "\n",
    "print('Shape of test set: ')\n",
    "print(y_test.shape)\n",
    "print('Number of test images that contain an airplane: ')\n",
    "print(y_test.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL: Perceptron\n",
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc.fit(data_train, y_train)\n",
    "\n",
    "prc_performance = my_measures.BinaryClassificationPerformance(prc.predict(data_train), y_train, 'prc')\n",
    "prc_performance.compute_measures()\n",
    "prc_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(prc_performance.performance_measures)\n",
    "\n",
    "prc_performance_test = my_measures.BinaryClassificationPerformance(prc.predict(data_test), y_test, 'prc')\n",
    "prc_performance_test.compute_measures()\n",
    "prc_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(prc_performance_test.performance_measures)\n",
    "\n",
    "prc_performance_test.img_indices()\n",
    "prc_img_indices_to_view = prc_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_examples(typ, measures):\n",
    "    iiv = ''\n",
    "    if typ == 'FP':\n",
    "        iiv = typ + '_indices'\n",
    "    elif typ == 'TP':\n",
    "        iiv = typ + '_indices'\n",
    "    elif typ == 'FN':\n",
    "        iiv = typ + '_indices'\n",
    "    else:\n",
    "        raise ValueError('input must be \"TP\", \"FP\", or \"FN\"')\n",
    "    for img in measures[iiv]:\n",
    "        print(imnames_list[img])\n",
    "        warnings.filterwarnings('ignore')    \n",
    "        plt.figure()\n",
    "        lookat = ci_path + imgs_test[img] + '.png' # location of original image\n",
    "        io.imshow(lookat) # show original image\n",
    "        plt.figure()\n",
    "        io.imshow(data_test[img].reshape(dims[0], dims[1])) # show manipulation for feature representation\n",
    "        warnings.filterwarnings('always')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at examples of Perceptron classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_examples('TP', prc_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_examples('FP', prc_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_examples('FN', prc_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train Multilayer Perceptron, a.k.a. neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "from sklearn import neural_network\n",
    "nn = neural_network.MLPClassifier(max_iter=1000)\n",
    "print(nn)\n",
    "nn.fit(data_train, y_train)\n",
    "\n",
    "nn_performance = my_measures.BinaryClassificationPerformance(nn.predict(data_train), y_train, 'nn')\n",
    "nn_performance.compute_measures()\n",
    "nn_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(nn_performance.performance_measures)\n",
    "\n",
    "nn_performance_test = my_measures.BinaryClassificationPerformance(nn.predict(data_test), y_test, 'nn_test')\n",
    "nn_performance_test.compute_measures()\n",
    "nn_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(nn_performance_test.performance_measures)\n",
    "\n",
    "nn_performance_test.img_indices()\n",
    "nn_img_indices_to_view = nn_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at examples of neural network classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_examples('TP', nn_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_examples('FP', nn_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FN_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-3174b13ac62d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperformance_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_img_indices_to_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-226-d3b03da12a54>\u001b[0m in \u001b[0;36mperformance_examples\u001b[0;34m(typ, measures)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input must be \"TP\", \"FP\", or \"FN\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miiv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimnames_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FN_indices'"
     ]
    }
   ],
   "source": [
    "performance_examples('FN', nn_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of fits to compare: \n",
    "final_fits = []\n",
    "final_fits.append(prc_performance.performance_measures)\n",
    "final_fits.append(prc_performance_test.performance_measures)\n",
    "final_fits.append(nn_performance.performance_measures)\n",
    "final_fits.append(nn_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for fit in final_fits:\n",
    "    if fit['set'] == 'train':\n",
    "        color = 'co'\n",
    "    else:\n",
    "        color = 'ro'\n",
    "    plt.plot(fit['FP'] / fit['Neg'], \n",
    "             fit['TP'] / fit['Pos'], color, markersize=12)\n",
    "    plt.text(fit['FP'] / fit['Neg'], \n",
    "             fit['TP'] / fit['Pos'], fit['desc'] + ': ' + fit['set'], fontsize=16)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
